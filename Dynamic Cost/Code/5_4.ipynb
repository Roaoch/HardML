{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-16.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "Collecting fastparquet\n",
      "  Using cached fastparquet-2024.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.8/site-packages (from pyarrow) (1.24.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from fastparquet) (21.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from fastparquet) (2024.3.1)\n",
      "Collecting cramjam>=2.3\n",
      "  Using cached cramjam-2.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from fastparquet) (1.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.5.0->fastparquet) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->fastparquet) (3.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Installing collected packages: pyarrow, cramjam, fastparquet\n",
      "Successfully installed cramjam-2.8.3 fastparquet-2024.2.0 pyarrow-16.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, Math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Импортируем библиотеки для визуализаци данных\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(\"model\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Оптимизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def log_uplifts(\n",
    "    constraints: Dict[str, float],\n",
    "    maximized_column: str,\n",
    "    optimal_statistics: Dict[str, float],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Функция для логирования значений метрик и их аплифтов (улучшений).\n",
    "\n",
    "    :param constraints: Словарь ограничений для метрик.\n",
    "    :param maximized_column: Название столбца, который подлежит максимизации.\n",
    "    :param optimal_statistics: Словарь с оптимальными статистическими данными.\n",
    "    \"\"\"\n",
    "    # Логируем значение метрики, которую мы максимизируем\n",
    "    logger.info(f\"Metric: {maximized_column}\", extra={\"value\": optimal_statistics.get(maximized_column)})\n",
    "\n",
    "    # Проходим по всем метрикам и их ограничениям\n",
    "    for metric, constraint in constraints.items():\n",
    "        optimal_value = optimal_statistics.get(metric)\n",
    "        if optimal_value is None:\n",
    "            raise ValueError(f\"`{metric}` has not been counted\")\n",
    "        # Логируем информацию по каждой метрике, включая аплифты\n",
    "        log_dict = {\n",
    "            \"constraint value\": round(constraint, 3),\n",
    "            \"optimal value\": round(optimal_value, 3),\n",
    "            \"uplift (abs)\": round(optimal_value - constraint, 3),\n",
    "            \"uplift (pct)\": round(optimal_value * 100 / constraint - 100, 3),\n",
    "        }\n",
    "        logger.info(f\"Metric: {metric}\")\n",
    "        for key, value in log_dict.items():\n",
    "            logger.info(f\"{key}= {value}\")\n",
    "\n",
    "\n",
    "def apply_constraints(\n",
    "    df: pd.DataFrame,\n",
    "    constraints: Dict[str, float],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Фильтруем датасет по заданным ограничениям.\n",
    "\n",
    "    :param df: DataFrame с данными для фильтрации.\n",
    "    :param constraints: Словарь ограничений для каждой метрики.\n",
    "    :return: Отфильтрованный DataFrame.\n",
    "    \"\"\"\n",
    "    # Применяем ограничения к датафрейму, фильтруя строки\n",
    "    for metric, constraint in constraints.items():\n",
    "        df = df[df[metric] >= constraint]\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_cum_lambda_metrics(\n",
    "    df: pd.DataFrame,\n",
    "    agg_columns: List[str],\n",
    "    maximized_column: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Считаем агрегированные значения метрик для каждой комбинации лямбда-значений.\n",
    "\n",
    "    :param df: DataFrame с данными.\n",
    "    :param agg_columns: Список столбцов для агрегации.\n",
    "    :param maximized_column: Столбец, который максимизируется.\n",
    "    :return: Агрегированный DataFrame.\n",
    "    \"\"\"\n",
    "    # Группируем данные по комбинации лямбда-значений и агрегируем указанные столбцы\n",
    "    df = df.groupby(\"lambda_combination\").agg({column: \"sum\" for column in agg_columns})\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def choose_optimal_values(\n",
    "    metric_lambda_map: Dict[str, float],\n",
    "    df: pd.DataFrame,\n",
    "    levels: List[str],\n",
    "    price_column: str,\n",
    "    maximized_column: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Находим оптимальные цены / наценки для каждого уровня для lambda_value\n",
    "    \"\"\"\n",
    "    # Считаем лагранжианы при lambda_value\n",
    "    df[\"lagrangian\"] = df[maximized_column]\n",
    "    lambda_combination_name = \"\"\n",
    "    for metric, metric_lambda in metric_lambda_map.items():\n",
    "        df[\"lagrangian\"] += df[metric] * metric_lambda\n",
    "        lambda_combination_name += f\"{metric}={metric_lambda}_\"\n",
    "    # Находим максимальный лагранжиан для каждого уровня\n",
    "    optimal_df = df.groupby(levels).agg({\"lagrangian\": \"max\"})\n",
    "    df = df.merge(optimal_df, on=levels + [\"lagrangian\"], how=\"inner\")\n",
    "    # Добавляем колонку с lambda_value для запоминания\n",
    "    df[\"lambda_combination\"] = lambda_combination_name.strip(\"_\")\n",
    "    # Удаляем дубликаты (например, оставляем минимальные цены / наценки из оптимальных),\n",
    "    # так как возможны одни и те же значения метрик для разных цен / наценок\n",
    "    # => одинаковые лагранжианы, а нам нужно выбрать одно значение для каждого уровня\n",
    "    df = df.sort_values(price_column)\n",
    "    df = df.drop_duplicates(subset=levels)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_metric_lambda_maps(lambda_config: Dict[str, Any]) -> List[Dict[str, float]]:\n",
    "    # Получаем список значений для каждого ключа\n",
    "    lambda_lists = list(lambda_config.values())\n",
    "    # Используем meshgrid для генерации всех комбинаций параметров\n",
    "    lambda_mesh = np.meshgrid(*lambda_lists)\n",
    "    # Преобразование в массив и решейпинг\n",
    "    lambda_vars = np.stack(lambda_mesh, axis=-1).reshape(-1, len(lambda_config))\n",
    "    # Создаем список словарей\n",
    "    metric_lambda_maps = [\n",
    "        dict(zip(lambda_config.keys(), combination)) for combination in lambda_vars\n",
    "    ]\n",
    "    return metric_lambda_maps\n",
    "\n",
    "\n",
    "def calculate_lagrangians(\n",
    "    df: pd.DataFrame,\n",
    "    lambda_config: Dict[str, Any],\n",
    "    levels: List[str],\n",
    "    price_column: str,\n",
    "    maximized_column: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Для каждого значения lambda находим оптимальные цены / наценки для каждого уровня\n",
    "    \"\"\"\n",
    "    lambda_dfs = []\n",
    "    metric_lambda_maps = get_metric_lambda_maps(lambda_config=lambda_config)\n",
    "    logger.info(\n",
    "        f\"Start calculating lagrangians, {len(metric_lambda_maps)} lambda combinations\"\n",
    "    )\n",
    "    for metric_lambda_map in metric_lambda_maps:\n",
    "        lambda_df = choose_optimal_values(\n",
    "            metric_lambda_map=metric_lambda_map,\n",
    "            df=df,\n",
    "            levels=levels,\n",
    "            price_column=price_column,\n",
    "            maximized_column=maximized_column,\n",
    "        )\n",
    "        lambda_dfs.append(lambda_df)\n",
    "    df = pd.concat(lambda_dfs)\n",
    "    df = df.reset_index(drop=True)\n",
    "    logger.info(f\"Ended calculating lagrangians\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Общая функция для оптимизации\n",
    "def optimize(\n",
    "    df: pd.DataFrame,\n",
    "    lambda_config: Dict[str, Any],\n",
    "    maximized_column: str,\n",
    "    constraints: Dict[str, float],\n",
    "    levels: List[str],\n",
    "    price_column: str,\n",
    ") -> pd.DataFrame:\n",
    "    logger.info(\"Start choosing optimal prices\")\n",
    "    lambda_df = calculate_lagrangians(\n",
    "        df=df,\n",
    "        lambda_config=lambda_config,\n",
    "        levels=levels,\n",
    "        price_column=price_column,\n",
    "        maximized_column=maximized_column,\n",
    "    )\n",
    "    statistics_df = calculate_cum_lambda_metrics(\n",
    "        df=lambda_df,\n",
    "        agg_columns=[maximized_column] + list(constraints.keys()),\n",
    "        maximized_column=maximized_column,\n",
    "    )\n",
    "    statistics_df = statistics_df.sort_values(maximized_column, ascending=False)\n",
    "    logger.info(f\"\\n{statistics_df.head()}\")\n",
    "    statistics_df = apply_constraints(df=statistics_df, constraints=constraints)\n",
    "    logger.info(f\"\\n{statistics_df.head()}\")\n",
    "    best_lambda = statistics_df[\"lambda_combination\"].tolist()[0]\n",
    "    optimal_statistics = statistics_df[\n",
    "        statistics_df[\"lambda_combination\"] == best_lambda\n",
    "    ].to_dict(orient=\"records\")[0]\n",
    "    optimal_df = lambda_df[lambda_df[\"lambda_combination\"] == best_lambda]\n",
    "    log_uplifts(\n",
    "        constraints=constraints,\n",
    "        maximized_column=maximized_column,\n",
    "        optimal_statistics=optimal_statistics,\n",
    "    )\n",
    "    logger.info(\"Ended choosing optimal prices\")\n",
    "    return optimal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Start choosing optimal prices\n",
      "INFO:__main__:Start calculating lagrangians, 121 lambda combinations\n",
      "INFO:__main__:Ended calculating lagrangians\n",
      "INFO:__main__:\n",
      "                   lambda_combination    orders_num  margin           gmv\n",
      "0                  margin=0.0_gmv=0.0  3.357924e+06     0.0  1.976511e+08\n",
      "6   margin=0.0_gmv=0.6000000000000001  3.357924e+06     0.0  1.976511e+08\n",
      "10                 margin=0.0_gmv=1.0  3.357924e+06     0.0  1.976511e+08\n",
      "9                  margin=0.0_gmv=0.9  3.357924e+06     0.0  1.976511e+08\n",
      "8                  margin=0.0_gmv=0.8  3.357924e+06     0.0  1.976511e+08\n",
      "INFO:__main__:\n",
      "                   lambda_combination    orders_num        margin  \\\n",
      "21                 margin=0.1_gmv=1.0  3.309405e+06  3.426072e+07   \n",
      "19                 margin=0.1_gmv=0.8  3.308614e+06  3.426947e+07   \n",
      "20                 margin=0.1_gmv=0.9  3.308614e+06  3.426947e+07   \n",
      "16                 margin=0.1_gmv=0.5  3.308614e+06  3.426947e+07   \n",
      "17  margin=0.1_gmv=0.6000000000000001  3.308614e+06  3.426947e+07   \n",
      "\n",
      "             gmv  \n",
      "21  1.973033e+08  \n",
      "19  1.973032e+08  \n",
      "20  1.973032e+08  \n",
      "16  1.973032e+08  \n",
      "17  1.973032e+08  \n",
      "INFO:__main__:Metric: orders_num\n",
      "INFO:__main__:Metric: margin\n",
      "INFO:__main__:constraint value= 19368542.125\n",
      "INFO:__main__:optimal value= 34260720.599\n",
      "INFO:__main__:uplift (abs)= 14892178.474\n",
      "INFO:__main__:uplift (pct)= 76.888\n",
      "INFO:__main__:Metric: gmv\n",
      "INFO:__main__:constraint value= 193685421.255\n",
      "INFO:__main__:optimal value= 197303312.127\n",
      "INFO:__main__:uplift (abs)= 3617890.873\n",
      "INFO:__main__:uplift (pct)= 1.868\n",
      "INFO:__main__:Ended choosing optimal prices\n"
     ]
    }
   ],
   "source": [
    "# Считаем ограничения\n",
    "df = pd.read_csv('./to_karp_5_3.csv')\n",
    "control_revenue = df[df[\"discount\"] == 0][[\"margin\", \"gmv\"]].sum()\n",
    "\n",
    "optimal_df = optimize(\n",
    "    df=df,\n",
    "    # перебираем разные lambda для выручки\n",
    "    lambda_config={\n",
    "        \"margin\": np.arange(0.0, 1.1, 0.1).tolist(),\n",
    "        \"gmv\": np.arange(0.0, 1.1, 0.1).tolist()\n",
    "    },\n",
    "    # указываем, что хотим максимизировать\n",
    "    maximized_column=\"orders_num\",\n",
    "    # указываем ограничения\n",
    "    constraints={\n",
    "        \"margin\": control_revenue[\"margin\"],\n",
    "        \"gmv\": control_revenue[\"gmv\"]\n",
    "    },\n",
    "    levels=[\"sku_id\", \"ds\"],\n",
    "    price_column=\"discount\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.1    0.924566\n",
       "-0.1    0.075434\n",
       "Name: discount, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим распределение скидок\n",
    "optimal_df[\"discount\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_id</th>\n",
       "      <th>discount</th>\n",
       "      <th>orders_num</th>\n",
       "      <th>gmv</th>\n",
       "      <th>margin</th>\n",
       "      <th>ds</th>\n",
       "      <th>lagrangian</th>\n",
       "      <th>lambda_combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166695</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2320.362976</td>\n",
       "      <td>31833.838469</td>\n",
       "      <td>6366.767694</td>\n",
       "      <td>20240101</td>\n",
       "      <td>34790.878215</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167102</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2331.617025</td>\n",
       "      <td>32563.472254</td>\n",
       "      <td>6512.694451</td>\n",
       "      <td>20240102</td>\n",
       "      <td>35546.358724</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167670</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2422.860191</td>\n",
       "      <td>37409.467858</td>\n",
       "      <td>7481.893572</td>\n",
       "      <td>20240103</td>\n",
       "      <td>40580.517406</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167428</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2501.122012</td>\n",
       "      <td>41366.607558</td>\n",
       "      <td>8273.321512</td>\n",
       "      <td>20240104</td>\n",
       "      <td>44695.061721</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166583</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2574.614243</td>\n",
       "      <td>41224.684283</td>\n",
       "      <td>8244.936857</td>\n",
       "      <td>20240105</td>\n",
       "      <td>44623.792212</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167429</th>\n",
       "      <td>401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1025.330837</td>\n",
       "      <td>104133.540277</td>\n",
       "      <td>20826.708055</td>\n",
       "      <td>20240103</td>\n",
       "      <td>107241.541919</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166584</th>\n",
       "      <td>401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1047.055648</td>\n",
       "      <td>124292.715808</td>\n",
       "      <td>24858.543162</td>\n",
       "      <td>20240104</td>\n",
       "      <td>127825.625772</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166526</th>\n",
       "      <td>401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1037.700417</td>\n",
       "      <td>114523.808942</td>\n",
       "      <td>22904.761788</td>\n",
       "      <td>20240105</td>\n",
       "      <td>117851.985538</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167005</th>\n",
       "      <td>401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1077.292167</td>\n",
       "      <td>118172.713031</td>\n",
       "      <td>23634.542606</td>\n",
       "      <td>20240106</td>\n",
       "      <td>121613.459458</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167775</th>\n",
       "      <td>401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1097.187596</td>\n",
       "      <td>121477.429447</td>\n",
       "      <td>24295.485889</td>\n",
       "      <td>20240107</td>\n",
       "      <td>125004.165632</td>\n",
       "      <td>margin=0.1_gmv=1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1498 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sku_id  discount   orders_num            gmv        margin        ds  \\\n",
       "166695       1       0.1  2320.362976   31833.838469   6366.767694  20240101   \n",
       "167102       1       0.1  2331.617025   32563.472254   6512.694451  20240102   \n",
       "167670       1       0.1  2422.860191   37409.467858   7481.893572  20240103   \n",
       "167428       1       0.1  2501.122012   41366.607558   8273.321512  20240104   \n",
       "166583       1       0.1  2574.614243   41224.684283   8244.936857  20240105   \n",
       "...        ...       ...          ...            ...           ...       ...   \n",
       "167429     401       0.1  1025.330837  104133.540277  20826.708055  20240103   \n",
       "166584     401       0.1  1047.055648  124292.715808  24858.543162  20240104   \n",
       "166526     401       0.1  1037.700417  114523.808942  22904.761788  20240105   \n",
       "167005     401       0.1  1077.292167  118172.713031  23634.542606  20240106   \n",
       "167775     401       0.1  1097.187596  121477.429447  24295.485889  20240107   \n",
       "\n",
       "           lagrangian  lambda_combination  \n",
       "166695   34790.878215  margin=0.1_gmv=1.0  \n",
       "167102   35546.358724  margin=0.1_gmv=1.0  \n",
       "167670   40580.517406  margin=0.1_gmv=1.0  \n",
       "167428   44695.061721  margin=0.1_gmv=1.0  \n",
       "166583   44623.792212  margin=0.1_gmv=1.0  \n",
       "...               ...                 ...  \n",
       "167429  107241.541919  margin=0.1_gmv=1.0  \n",
       "166584  127825.625772  margin=0.1_gmv=1.0  \n",
       "166526  117851.985538  margin=0.1_gmv=1.0  \n",
       "167005  121613.459458  margin=0.1_gmv=1.0  \n",
       "167775  125004.165632  margin=0.1_gmv=1.0  \n",
       "\n",
       "[1498 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_df.sort_values(['sku_id', 'ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_df[[\n",
    "    'sku_id',\n",
    "    'discount',\n",
    "    'ds'\n",
    "]].to_csv('to_karp_5_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control margin: 19368542 руб.\n",
      "Test margin: 34260721 руб.\n",
      "Uplift: 77 %\n",
      "Control revenue: 193685421 руб.\n",
      "Test revenue: 197303312 руб.\n",
      "Uplift: 2 %\n"
     ]
    }
   ],
   "source": [
    "# Считаем аплифт на предсказаниях\n",
    "control_margin = df[df[\"discount\"] == 0][\"margin\"].sum()\n",
    "control_revenue = df[df[\"discount\"] == 0][\"gmv\"].sum()\n",
    "\n",
    "test_margin = optimal_df[\"margin\"].sum()\n",
    "test_revenue = optimal_df[\"gmv\"].sum()\n",
    "\n",
    "print(f\"Control margin: {round(control_margin)} руб.\")\n",
    "print(f\"Test margin: {round(test_margin)} руб.\")\n",
    "print(f\"Uplift: {round(test_margin * 100 / control_margin - 100)} %\")\n",
    "\n",
    "print(f\"Control revenue: {round(control_revenue)} руб.\")\n",
    "print(f\"Test revenue: {round(test_revenue)} руб.\")\n",
    "print(f\"Uplift: {round(test_revenue * 100 / control_revenue - 100)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
